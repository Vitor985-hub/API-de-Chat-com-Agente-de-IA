# ğŸ’¬ API de Chat com Agente de IA 

Esta aplicaÃ§Ã£o implementa uma API FastAPI que expÃµe um endpoint de chat integrado a um agente Strands, utilizando um modelo rodando no Ollama com suporte a tools (funÃ§Ãµes externas).
Permite enviar mensagens para o agente e receber respostas estruturadas.
---

# ğŸ“¦ Tecnologias utilizadas

FastAPI â€” Framework para construÃ§Ã£o de APIs rÃ¡pidas em Python

Strands Agents â€” Framework para criaÃ§Ã£o de agentes com ferramentas

Ollama â€” ExecuÃ§Ã£o local de modelos LLM

Uvicorn â€” Servidor ASGI

Python 3.11+

---

# ğŸ“‚ Estrutura do Projeto
````
.
â”œâ”€â”€ main.py # API FastAPI
â”œâ”€â”€ agent.py # ConfiguraÃ§Ã£o do agente de IA
â”œâ”€â”€ tools.py # Tool de cÃ¡lculo matemÃ¡tico
â”œâ”€â”€ config.py # Carrega variÃ¡veis do .env
â”œâ”€â”€ requirements.txt # DependÃªncias
â”œâ”€â”€ .env # ConfiguraÃ§Ãµes do modelo LLM
â””â”€â”€ README.md.
````

---
âš™ï¸ PrÃ©-requisitos

Antes de executar a API, instale:

âœ”ï¸ Python 3.11+
âœ”ï¸ Ollama instalado

Baixe em: https://ollama.com/download

âœ”ï¸ Baixe um modelo compatÃ­vel com tools

Recomendado:
````
ollama pull llama3.1
````

Ou outro modelo que vocÃª definir no .env.

---
# âš™ï¸ InstalaÃ§Ã£o e ExecuÃ§Ã£o

ğŸ“¦ InstalaÃ§Ã£o
1ï¸âƒ£ Crie o ambiente virtual
python -m venv .venv

2ï¸âƒ£ Ative o ambiente

Windows:
````
.venv\Scripts\activate
````
3ï¸âƒ£ Instale as dependÃªncias
````
pip install -r requirements.txt
````
â–¶ï¸ Executando a API

Com tudo configurado, rode:
````
uvicorn main:app --reload
````

A API estarÃ¡ disponÃ­vel em:

ğŸ“ http://127.0.0.1:8000

DocumentaÃ§Ã£o interativa:

ğŸ“„ http://127.0.0.1:8000/docs


---

# ğŸš€ Testando o Endpoint

Exemplo usando curl:
````
curl -X POST "http://127.0.0.1:8000/chat" \
-H "Content-Type: application/json" \
-d "{\"Message\": \"OlÃ¡, quem Ã© vocÃª?\"}"
````
Resposta esperada:
````
{
  "response": {
    "message": {
      "role": "assistant",
      "content": [
        { "text": "OlÃ¡! Eu sou seu agente de IA..." }
      ]
    }
  }
}
````
---
ğŸ§  Funcionamento do Agente

O agente funciona assim:

Recebe a entrada enviada via /chat

Se identificar expressÃ£o matemÃ¡tica â†’ usa a MathTool

Caso contrÃ¡rio â†’ responde usando o modelo LLM

Retorna a resposta no formato JSON

---
ğŸ›  Exemplos de Perguntas
MatemÃ¡tica:

"Quanto Ã© 2 + 2?"

"Qual a raiz quadrada de 144?"

"1234 * 5678?"

Gerais:

"Quem foi Albert Einstein?"

"Explique o que Ã© aprendizado de mÃ¡quina."

"Qual Ã© a capital da ItÃ¡lia?"

---

ğŸ“ ConsideraÃ§Ãµes Finais

Este projeto foi desenvolvido como um desafio tÃ©cnico, com foco em:

simplicidade

clareza

organizaÃ§Ã£o

boas prÃ¡ticas

entendimento real do fluxo entre API â†” Agente â†” Tool

O cÃ³digo foi mantido o mais direto possÃ­vel para facilitar manutenÃ§Ã£o e estudo.

---
ğŸ‘¤ Autor

Vitor Eiji

GitHub:
````
https://github.com/Vitor985-hub
````
