# ğŸ’¬ API de Chat com Agente de IA (FastAPI + Strands Agents + Ollama)

Este projeto implementa uma API de **chat** simples que se conecta a um **Agente de IA**.  
O agente Ã© capaz de:

- Responder perguntas gerais usando um modelo de linguagem local via **Ollama**  
- Detectar quando a pergunta envolve matemÃ¡tica  
- Usar uma **Tool de CÃ¡lculo** para realizar operaÃ§Ãµes matemÃ¡ticas

O projeto Ã© estruturado de forma **simples, limpa e fÃ¡cil de manter**, seguindo boas prÃ¡ticas de organizaÃ§Ã£o.

---

# ğŸ“Œ Tecnologias Utilizadas

- **Python 3.10+**
- **FastAPI** â€” criaÃ§Ã£o da API
- **Strands Agents SDK** â€” agente de IA e gestÃ£o de ferramentas
- **Ollama** â€” execuÃ§Ã£o local do modelo LLM
- **python-dotenv** â€” leitura de variÃ¡veis de ambiente
- **Uvicorn** â€” servidor ASGI

---

# ğŸ“‚ Estrutura do Projeto
````
.
â”œâ”€â”€ main.py # API FastAPI
â”œâ”€â”€ agent.py # ConfiguraÃ§Ã£o do agente de IA
â”œâ”€â”€ tools.py # Tool de cÃ¡lculo matemÃ¡tico
â”œâ”€â”€ config.py # Carrega variÃ¡veis do .env
â”œâ”€â”€ requirements.txt # DependÃªncias
â”œâ”€â”€ .env # ConfiguraÃ§Ãµes do modelo LLM
â””â”€â”€ README.md.
````

---

# âš™ï¸ InstalaÃ§Ã£o e ExecuÃ§Ã£o

## 1ï¸âƒ£ Criar e ativar um ambiente virtual (opcional, mas recomendado)

### Windows
````
python -m venv .venv
````
Ative o ambiente
````
.venv\Scripts\activate
````

### Linux/Mac
````
python3 -m venv .venv
````
````
source .venv/bin/activate
````
---

## 2ï¸âƒ£ Instalar dependÃªncias

````
pip install -r requirements.txtpip install -r requirements.txt
````

---

## 3ï¸âƒ£ Instalar e configurar o Ollama

Instale o Ollama:

ğŸ‘‰ https://ollama.com/download

Baixe o modelo (usei "llama3", mas pode ser outro):
````
ollama pull llama3
````

Inicie o servidor:
````
ollama serve
````

---

## 4ï¸âƒ£ Executar a API
````
uvicorn main:app --reload
````

A API ficarÃ¡ disponÃ­vel em:

ğŸ‘‰ **http://localhost:8000**

---

# ğŸš€ Testando o Endpoint

### Rota:
````
POST /chat
````

### Corpo da requisiÃ§Ã£o (JSON):
```
{
  "message": "Quanto Ã© 1234 * 5678?"
}
```
Resposta esperada:
````
{
  "response": "7006652"
}
````
---
ğŸ§  Funcionamento do Agente

O agente funciona assim:

Recebe a entrada enviada via /chat

Se identificar expressÃ£o matemÃ¡tica â†’ usa a MathTool

Caso contrÃ¡rio â†’ responde usando o modelo LLM

Retorna a resposta no formato JSON

---
ğŸ›  Exemplos de Perguntas
MatemÃ¡tica:

"Quanto Ã© 2 + 2?"

"Qual a raiz quadrada de 144?"

"1234 * 5678?"

Gerais:

"Quem foi Albert Einstein?"

"Explique o que Ã© aprendizado de mÃ¡quina."

"Qual Ã© a capital da ItÃ¡lia?"

---

ğŸ“ ConsideraÃ§Ãµes Finais

Este projeto foi desenvolvido como um desafio tÃ©cnico, com foco em:

simplicidade

clareza

organizaÃ§Ã£o

boas prÃ¡ticas

entendimento real do fluxo entre API â†” Agente â†” Tool

O cÃ³digo foi mantido o mais direto possÃ­vel para facilitar manutenÃ§Ã£o e estudo.

---
ğŸ‘¤ Autor

Vitor Eiji

GitHub:
````
https://github.com/Vitor985-hub
````
